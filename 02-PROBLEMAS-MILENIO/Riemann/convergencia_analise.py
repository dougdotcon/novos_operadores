#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AN√ÅLISE DE CONVERG√äNCIA: œÉ_min ‚Üí 1/2 quando n ‚Üí ‚àû
==================================================

Quest√£o cr√≠tica:
  œÉ_min = 0.50026 (erro ~2.6e-4) com 50 zeros
  
  Isso √©:
  (a) Erro num√©rico que desaparece com mais zeros?
  (b) Evid√™ncia de que œÉ_min ‚â† 1/2 exatamente?

Teste: Calcular œÉ_min para n = 10, 20, 30, ..., 100
       e verificar se œÉ_min(n) ‚Üí 0.5 quando n ‚Üí ‚àû
"""

import numpy as np
import mpmath as mp
from scipy.optimize import minimize_scalar
import matplotlib.pyplot as plt

mp.dps = 80  # Aumentar precis√£o para 80 d√≠gitos!

def zeta_zeros(n_zeros):
    """Primeiros n_zeros de Œ∂ com ALTA precis√£o"""
    zeros = []
    for n in range(1, n_zeros + 1):
        gamma = mp.zetazero(n)
        zeros.append(complex(gamma))
    return zeros

def F_functional(sigma, zeros):
    """Funcional variacional F[œÉ]"""
    n = len(zeros)
    
    # F1: Simetria
    F1 = n * abs(2*sigma - 1.0)**2
    
    # F2: Equa√ß√£o funcional
    F2 = 0.0
    for gamma in zeros:
        t = gamma.imag
        s = complex(sigma, t)
        
        try:
            chi_s = (2**s * mp.pi**(s-1) * mp.sin(mp.pi*s/2) * mp.gamma(1-s))
            violation = abs(1.0 - abs(chi_s))
            F2 += violation**2
        except:
            F2 += 1000.0
    
    # F3: GUE energia
    F3 = 0.0
    for i, zi in enumerate(zeros):
        for j, zj in enumerate(zeros):
            if i < j:
                ti, tj = zi.imag, zj.imag
                dist = np.sqrt((ti - tj)**2 + 0.01)
                F3 += -np.log(dist)
    
    if n > 1:
        F3 = F3 / (n * (n-1) / 2)
    
    # Pesos
    w1, w2, w3 = 100.0, 10.0, 1.0
    
    return float(w1 * F1/n + w2 * F2/n + w3 * F3)

def find_minimum(zeros, method='bounded'):
    """Encontra œÉ_min com alta precis√£o"""
    
    def objective(sigma):
        if isinstance(sigma, np.ndarray):
            sigma = sigma[0]
        return F_functional(sigma, zeros)
    
    # M√∫ltiplas otimiza√ß√µes para garantir converg√™ncia
    results = []
    
    # M√©todo 1: Bounded
    res1 = minimize_scalar(objective, bounds=(0.4, 0.6), method='bounded', 
                          options={'xatol': 1e-12})
    results.append(res1.x)
    
    # M√©todo 2: Brent (golden section) sem bounds
    res2 = minimize_scalar(objective, bracket=(0.45, 0.5, 0.55), method='brent',
                          options={'xtol': 1e-12})
    results.append(res2.x)
    
    # M√©todo 3: Grid refinement
    grid = np.linspace(0.49, 0.51, 1000)
    F_values = [objective(s) for s in grid]
    idx_min = np.argmin(F_values)
    results.append(grid[idx_min])
    
    # Retorna m√©dia (mais robusto)
    sigma_min = np.mean(results)
    F_min = objective(sigma_min)
    
    return sigma_min, F_min, np.std(results)

def convergence_analysis():
    """
    Analisa converg√™ncia œÉ_min(n) ‚Üí 0.5 quando n ‚Üí ‚àû
    
    Se RH √© verdadeira e F captura a f√≠sica correta,
    esperamos œÉ_min(n) = 0.5 + O(1/n) ou melhor
    """
    print("="*80)
    print(" AN√ÅLISE DE CONVERG√äNCIA: œÉ_min(n) ‚Üí 1/2?")
    print("="*80)
    print(f"Precis√£o: {mp.dps} d√≠gitos decimais")
    print(f"M√©todos: Bounded + Brent + Grid (m√©dia)\n")
    
    n_values = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]
    sigma_mins = []
    F_mins = []
    errors = []
    stds = []
    
    print("n      œÉ_min          |œÉ_min - 1/2|      F[œÉ_min]      std_dev")
    print("-" * 75)
    
    for n in n_values:
        print(f"{n:3d}  ", end='', flush=True)
        
        zeros = zeta_zeros(n)
        sigma_min, F_min, std = find_minimum(zeros)
        
        error = abs(sigma_min - 0.5)
        
        sigma_mins.append(sigma_min)
        F_mins.append(F_min)
        errors.append(error)
        stds.append(std)
        
        print(f"{sigma_min:.10f}   {error:.2e}   {F_min:10.6f}   {std:.2e}")
    
    # An√°lise de tend√™ncia
    print("\n" + "="*80)
    print(" AN√ÅLISE DE TEND√äNCIA")
    print("="*80)
    
    # Fit linear: œÉ_min(n) = a + b/n
    n_array = np.array(n_values)
    sigma_array = np.array(sigma_mins)
    
    # Regress√£o em 1/n
    X = np.vstack([np.ones(len(n_array)), 1.0/n_array]).T
    coeffs = np.linalg.lstsq(X, sigma_array, rcond=None)[0]
    
    a_fit = coeffs[0]  # Limite quando n ‚Üí ‚àû
    b_fit = coeffs[1]  # Coeficiente de 1/n
    
    print(f"\nModelo: œÉ_min(n) = a + b/n")
    print(f"  a = {a_fit:.12f}  (limite n ‚Üí ‚àû)")
    print(f"  b = {b_fit:.12f}")
    print(f"\n  |a - 0.5| = {abs(a_fit - 0.5):.2e}")
    
    # Extrapola√ß√£o para n grande
    print(f"\nExtrapola√ß√£o:")
    for n_ext in [200, 500, 1000, 10000]:
        sigma_ext = a_fit + b_fit/n_ext
        print(f"  n = {n_ext:5d}  ‚Üí  œÉ_min ‚âà {sigma_ext:.12f}")
    
    # Teste de converg√™ncia
    print("\n" + "="*80)
    
    converges = abs(a_fit - 0.5) < 1e-6
    
    if converges:
        print(" ‚úì CONVERG√äNCIA CONFIRMADA!")
        print(f"\n   lim_{'{n‚Üí‚àû}'} œÉ_min(n) = {a_fit:.10f} ‚âà 1/2")
        print(f"\n   Taxa: œÉ_min(n) - 1/2 = O(1/n)")
        print(f"   Coeficiente: {b_fit:.6f}/n")
    else:
        print(" ‚úó CONVERG√äNCIA DUVIDOSA")
        print(f"\n   lim œÉ_min = {a_fit:.10f}")
        print(f"   Desvio de 1/2: {abs(a_fit - 0.5):.2e}")
    
    print("="*80 + "\n")
    
    return n_values, sigma_mins, errors, a_fit, b_fit

def plot_convergence(n_values, sigma_mins, errors, a_fit, b_fit):
    """Visualiza converg√™ncia para œÉ = 1/2"""
    
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    fig.suptitle('Converg√™ncia: œÉ_min(n) ‚Üí 1/2 quando n ‚Üí ‚àû', 
                 fontsize=16, fontweight='bold')
    
    # Plot 1: œÉ_min vs n
    ax = axes[0, 0]
    ax.plot(n_values, sigma_mins, 'bo-', markersize=8, linewidth=2, label='œÉ_min(n)')
    ax.axhline(0.5, color='r', linestyle='--', linewidth=2, label='œÉ = 1/2 (RH)')
    
    # Fit
    n_fit = np.linspace(min(n_values), max(n_values), 200)
    sigma_fit = a_fit + b_fit / n_fit
    ax.plot(n_fit, sigma_fit, 'g--', linewidth=2, alpha=0.7, 
            label=f'Fit: {a_fit:.4f} + {b_fit:.2f}/n')
    
    ax.set_xlabel('N√∫mero de zeros (n)', fontsize=12)
    ax.set_ylabel('œÉ_min', fontsize=12)
    ax.set_title('M√≠nimo vs N√∫mero de Zeros', fontsize=12, fontweight='bold')
    ax.legend(fontsize=10)
    ax.grid(True, alpha=0.3)
    
    # Plot 2: Erro |œÉ_min - 0.5|
    ax = axes[0, 1]
    ax.semilogy(n_values, errors, 'ro-', markersize=8, linewidth=2, label='|œÉ_min - 1/2|')
    
    # Curva 1/n para refer√™ncia
    error_fit = abs(b_fit) / np.array(n_values)
    ax.semilogy(n_values, error_fit, 'g--', linewidth=2, alpha=0.7, label='O(1/n)')
    
    ax.set_xlabel('N√∫mero de zeros (n)', fontsize=12)
    ax.set_ylabel('|œÉ_min - 1/2|', fontsize=12)
    ax.set_title('Erro Absoluto (escala log)', fontsize=12, fontweight='bold')
    ax.legend(fontsize=10)
    ax.grid(True, alpha=0.3)
    
    # Plot 3: Res√≠duo do fit
    ax = axes[1, 0]
    sigma_fit_values = a_fit + b_fit / np.array(n_values)
    residuals = np.array(sigma_mins) - sigma_fit_values
    ax.plot(n_values, residuals * 1e6, 'mo-', markersize=8, linewidth=2)
    ax.axhline(0, color='k', linestyle=':', alpha=0.5)
    ax.set_xlabel('N√∫mero de zeros (n)', fontsize=12)
    ax.set_ylabel('Res√≠duo √ó 10‚Å∂', fontsize=12)
    ax.set_title('Qualidade do Fit (a + b/n)', fontsize=12, fontweight='bold')
    ax.grid(True, alpha=0.3)
    
    # Plot 4: Extrapola√ß√£o
    ax = axes[1, 1]
    n_ext = np.array([10, 20, 30, 50, 100, 200, 500, 1000, 2000, 5000, 10000])
    sigma_ext = a_fit + b_fit / n_ext
    error_ext = np.abs(sigma_ext - 0.5)
    
    ax.loglog(n_ext, error_ext, 'b^-', markersize=8, linewidth=2, label='|œÉ_min - 1/2|')
    ax.loglog(n_ext, 1.0/n_ext, 'r--', linewidth=2, alpha=0.7, label='1/n')
    ax.loglog(n_ext, 1.0/n_ext**2, 'g--', linewidth=2, alpha=0.7, label='1/n¬≤')
    
    ax.set_xlabel('n (escala log)', fontsize=12)
    ax.set_ylabel('Erro (escala log)', fontsize=12)
    ax.set_title('Extrapola√ß√£o para n grande', fontsize=12, fontweight='bold')
    ax.legend(fontsize=10)
    ax.grid(True, alpha=0.3, which='both')
    
    plt.tight_layout()
    plt.savefig('convergencia_sigma_min.png', dpi=300, bbox_inches='tight')
    print("[Visualiza√ß√£o salva: convergencia_sigma_min.png]\n")
    plt.close()

def main():
    """An√°lise completa de converg√™ncia"""
    
    print("\n" + "üî¨"*40)
    print("\n  TESTE DEFINITIVO: œÉ_min ‚Üí 1/2 quando n ‚Üí ‚àû?")
    print("\n" + "üî¨"*40 + "\n")
    
    # Executar an√°lise
    n_values, sigma_mins, errors, a_fit, b_fit = convergence_analysis()
    
    # Visualizar
    plot_convergence(n_values, sigma_mins, errors, a_fit, b_fit)
    
    # Conclus√£o
    print("="*80)
    print(" CONCLUS√ÉO FINAL")
    print("="*80)
    
    if abs(a_fit - 0.5) < 1e-6:
        print("\n‚úì‚úì‚úì CONVERG√äNCIA PARA œÉ = 1/2 CONFIRMADA! ‚úì‚úì‚úì\n")
        print(f"  lim œÉ_min(n) = {a_fit:.10f}")
        print(f"  n‚Üí‚àû")
        print(f"\n  Erro: |{a_fit:.10f} - 0.5| = {abs(a_fit - 0.5):.2e} < 10‚Åª‚Å∂")
        print(f"\n  Interpreta√ß√£o:")
        print(f"    Com infinitos zeros, o funcional F[œÉ]")
        print(f"    minimiza EXATAMENTE em œÉ = 1/2")
        print(f"\n  ‚üπ Princ√≠pio Variacional FAVORECE RH!\n")
    else:
        print("\n‚úó Converg√™ncia n√£o para œÉ = 1/2 exatamente")
        print(f"\n  lim œÉ_min = {a_fit:.10f}")
        print(f"  Desvio: {abs(a_fit - 0.5):.2e}")
    
    print("="*80 + "\n")

if __name__ == "__main__":
    main()
